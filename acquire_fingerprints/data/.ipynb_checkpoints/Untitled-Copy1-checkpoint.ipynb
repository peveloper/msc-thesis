{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import welch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'70295915', '80033394', '70264803', '80091938', '80031611', '70021636', '70123920', '80075563', '70243464', '80093106', '896970', '80216161', '80052541', '70142827', '80184131', '70213513', '70305893', '80091879', '80174429', '80192815', '60026145', '80216758', '80986885', '80096067', '70298735', '70097579', '80134721', '70251536', '81006261', '80991158', '80009431', '80183328', '81080637', '80101827', '80013870', '70043945', '14607635', '80128722', '70129581', '60004473', '70041162', '70216224', '80018689', '80135164', '70220028', '80163052', '80192445', '80232502', '81074663', '80037110', '70112732', '70289949', '80029196', '70243461', '80232501', '70103763', '70217908', '70011204', '70283202', '80064513', '70109893', '80121840', '80210932', '80168188', '80031715', '70075480', '80085316', '60031214', '60027695', '70044686', '80000643', '80102952', '80097391', '80106307', '70308063', '80091741', '70087537', '70308278', '80202920'}\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('[0-9]*_[0-9]*.dat')\n",
    "distinct_files = set()\n",
    "for file in files:\n",
    "    distinct_files.add(file.split('_')[0])\n",
    "print(distinct_files)\n",
    "df_list = [pd.read_table(file, header=None, names=['Segment', '%s' % file.split('.')[0]], index_col=0) for file in files]\n",
    "big_df = pd.concat(df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft_values(y_values, T, N, f_s):\n",
    "    f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    return f_values, fft_values\n",
    " \n",
    "def get_psd_values(y_values, T, N, f_s):\n",
    "    f_values, psd_values = welch(y_values, fs=f_s)\n",
    "    return f_values, psd_values\n",
    "\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]\n",
    " \n",
    "def get_cor_values(y_values, T, N, f_s):\n",
    "    autocorr_values = autocorr(y_values)\n",
    "    x_values = np.array([T * jj for jj in range(0, N)])\n",
    "    return x_values, autocorr_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect peaks in data based on their amplitude and other features.\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "\n",
    "__author__ = \"Marcos Duarte, https://github.com/demotu/BMC\"\n",
    "__version__ = \"1.0.5\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='rising',\n",
    "                 kpsh=False, valley=False, show=False, ax=None):\n",
    "\n",
    "    \"\"\"Detect peaks in data based on their amplitude and other features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array_like\n",
    "        data.\n",
    "    mph : {None, number}, optional (default = None)\n",
    "        detect peaks that are greater than minimum peak height (if parameter\n",
    "        `valley` is False) or peaks that are smaller than maximum peak height\n",
    "         (if parameter `valley` is True).\n",
    "    mpd : positive integer, optional (default = 1)\n",
    "        detect peaks that are at least separated by minimum peak distance (in\n",
    "        number of data).\n",
    "    threshold : positive number, optional (default = 0)\n",
    "        detect peaks (valleys) that are greater (smaller) than `threshold`\n",
    "        in relation to their immediate neighbors.\n",
    "    edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
    "        for a flat peak, keep only the rising edge ('rising'), only the\n",
    "        falling edge ('falling'), both edges ('both'), or don't detect a\n",
    "        flat peak (None).\n",
    "    kpsh : bool, optional (default = False)\n",
    "        keep peaks with same height even if they are closer than `mpd`.\n",
    "    valley : bool, optional (default = False)\n",
    "        if True (1), detect valleys (local minima) instead of peaks.\n",
    "    show : bool, optional (default = False)\n",
    "        if True (1), plot data in matplotlib figure.\n",
    "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ind : 1D array_like\n",
    "        indeces of the peaks in `x`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The detection of valleys instead of peaks is performed internally by simply\n",
    "    negating the data: `ind_valleys = detect_peaks(-x)`\n",
    "    \n",
    "    The function can handle NaN's \n",
    "\n",
    "    See this IPython Notebook [1]_.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from detect_peaks import detect_peaks\n",
    "    >>> x = np.random.randn(100)\n",
    "    >>> x[60:81] = np.nan\n",
    "    >>> # detect all peaks and plot data\n",
    "    >>> ind = detect_peaks(x, show=True)\n",
    "    >>> print(ind)\n",
    "\n",
    "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    >>> # set minimum peak height = 0 and minimum peak distance = 20\n",
    "    >>> detect_peaks(x, mph=0, mpd=20, show=True)\n",
    "\n",
    "    >>> x = [0, 1, 0, 2, 0, 3, 0, 2, 0, 1, 0]\n",
    "    >>> # set minimum peak distance = 2\n",
    "    >>> detect_peaks(x, mpd=2, show=True)\n",
    "\n",
    "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    >>> # detection of valleys instead of peaks\n",
    "    >>> detect_peaks(x, mph=-1.2, mpd=20, valley=True, show=True)\n",
    "\n",
    "    >>> x = [0, 1, 1, 0, 1, 1, 0]\n",
    "    >>> # detect both edges\n",
    "    >>> detect_peaks(x, edge='both', show=True)\n",
    "\n",
    "    >>> x = [-2, 1, -2, 2, 1, 1, 3, 0]\n",
    "    >>> # set threshold = 2\n",
    "    >>> detect_peaks(x, threshold = 2, show=True)\n",
    "\n",
    "    Version history\n",
    "    ---------------\n",
    "    '1.0.5':\n",
    "        The sign of `mph` is inverted if parameter `valley` is True\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    x = np.atleast_1d(x).astype('float64')\n",
    "    if x.size < 3:\n",
    "        return np.array([], dtype=int)\n",
    "    if valley:\n",
    "        x = -x\n",
    "        if mph is not None:\n",
    "            mph = -mph\n",
    "    # find indices of all peaks\n",
    "    dx = x[1:] - x[:-1]\n",
    "    # handle NaN's\n",
    "    indnan = np.where(np.isnan(x))[0]\n",
    "    if indnan.size:\n",
    "        x[indnan] = np.inf\n",
    "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "    if not edge:\n",
    "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "    else:\n",
    "        if edge.lower() in ['rising', 'both']:\n",
    "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        if edge.lower() in ['falling', 'both']:\n",
    "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "    # handle NaN's\n",
    "    if ind.size and indnan.size:\n",
    "        # NaN's and values close to NaN's cannot be peaks\n",
    "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan-1, indnan+1))), invert=True)]\n",
    "    # first and last values of x cannot be peaks\n",
    "    if ind.size and ind[0] == 0:\n",
    "        ind = ind[1:]\n",
    "    if ind.size and ind[-1] == x.size-1:\n",
    "        ind = ind[:-1]\n",
    "    # remove peaks < minimum peak height\n",
    "    if ind.size and mph is not None:\n",
    "        ind = ind[x[ind] >= mph]\n",
    "    # remove peaks - neighbors < threshold\n",
    "    if ind.size and threshold > 0:\n",
    "        dx = np.min(np.vstack([x[ind]-x[ind-1], x[ind]-x[ind+1]]), axis=0)\n",
    "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "    # detect small peaks closer than minimum peak distance\n",
    "    if ind.size and mpd > 1:\n",
    "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "        idel = np.zeros(ind.size, dtype=bool)\n",
    "        for i in range(ind.size):\n",
    "            if not idel[i]:\n",
    "                # keep peaks with the same height if kpsh is True\n",
    "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                    & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                idel[i] = 0  # Keep current peak\n",
    "        # remove the small peaks and sort back the indices by their occurrence\n",
    "        ind = np.sort(ind[~idel])\n",
    "\n",
    "    if show:\n",
    "        if indnan.size:\n",
    "            x[indnan] = np.nan\n",
    "        if valley:\n",
    "            x = -x\n",
    "            if mph is not None:\n",
    "                mph = -mph\n",
    "        _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
    "\n",
    "    return ind\n",
    "\n",
    "\n",
    "def _plot(x, mph, mpd, threshold, edge, valley, ax, ind):\n",
    "    \"\"\"Plot results of the detect_peaks function, see its help.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        print('matplotlib is not available.')\n",
    "    else:\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "        ax.plot(x, 'b', lw=1)\n",
    "        if ind.size:\n",
    "            label = 'valley' if valley else 'peak'\n",
    "            label = label + 's' if ind.size > 1 else label\n",
    "            ax.plot(ind, x[ind], '+', mfc=None, mec='r', mew=2, ms=8,\n",
    "                    label='%d %s' % (ind.size, label))\n",
    "            ax.legend(loc='best', framealpha=.5, numpoints=1)\n",
    "        ax.set_xlim(-.02*x.size, x.size*1.02-1)\n",
    "        ymin, ymax = x[np.isfinite(x)].min(), x[np.isfinite(x)].max()\n",
    "        yrange = ymax - ymin if ymax > ymin else 1\n",
    "        ax.set_ylim(ymin - 0.1*yrange, ymax + 0.1*yrange)\n",
    "        ax.set_xlabel('Data #', fontsize=14)\n",
    "        ax.set_ylabel('Amplitude', fontsize=14)\n",
    "        mode = 'Valley detection' if valley else 'Peak detection'\n",
    "        ax.set_title(\"%s (mph=%s, mpd=%d, threshold=%s, edge='%s')\"\n",
    "                     % (mode, str(mph), mpd, str(threshold), edge))\n",
    "        # plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 76, using nperseg = 76\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 78, using nperseg = 78\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 88, using nperseg = 88\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 66, using nperseg = 66\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 67, using nperseg = 67\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 81, using nperseg = 81\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 41, using nperseg = 41\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 2, using nperseg = 2\n",
      "  .format(nperseg, input_length))\n",
      "/home/peveloper/.local/lib/python3.6/site-packages/scipy/signal/spectral.py:1969: UserWarning: nperseg = 256 is greater than input length  = 59, using nperseg = 59\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d20d0ed0146d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mt_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_n\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mf_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "features = 15\n",
    "data = np.zeros((len(big_df.columns), (features * 2) + 1))\n",
    "\n",
    "i=0\n",
    "k=0\n",
    "\n",
    "for file in sorted(big_df.columns):\n",
    "    id = file.split('_')[0]\n",
    "    tp = file.split('_')[-1]\n",
    "    \n",
    "    column = big_df[file].dropna()\n",
    "    t_n = 0.1\n",
    "    N = column.shape[0]\n",
    "    T = t_n / N\n",
    "    f_s = 1 / T  \n",
    "    \n",
    "    x, y = get_fft_values(column, T, N, f_s)\n",
    "    idxs = detect_peaks(y)[:5]\n",
    "\n",
    "    for z, el in enumerate(idxs):\n",
    "        x[z] = x[el]\n",
    "        y[z] = y[el]\n",
    "        data[i][z + k] = x[z]\n",
    "        data[i][z + k + 1] = y[z]\n",
    "        k+=1\n",
    "\n",
    "    k+=z+1\n",
    "    x, y = get_psd_values(column, T, N, f_s)\n",
    "    idxs = detect_peaks(y)[:5]\n",
    "\n",
    "    for z, el in enumerate(idxs):\n",
    "        x[z] = x[el]\n",
    "        y[z] = y[el]\n",
    "        data[i][z + k] = x[z]\n",
    "        data[i][z + k + 1] = y[z]\n",
    "        k+=1\n",
    "        \n",
    "    k+=z+1\n",
    "    x, y = get_cor_values(column, T, N, f_s)\n",
    "    idxs = detect_peaks(y)[:5]\n",
    "\n",
    "    for z, el in enumerate(idxs):\n",
    "        x[z] = x[el]\n",
    "        y[z] = y[el]\n",
    "        data[i][z + k] = x[z]\n",
    "        data[i][z + k + 1] = y[z]\n",
    "        k+=1\n",
    "        \n",
    "    k+=z+1\n",
    "    data[i][k] = int(file)\n",
    "        \n",
    "    i+=1\n",
    "    k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.07692308e+01, 1.11518675e+05, 7.17948718e+01, 3.81782941e+04,\n",
       "       1.02564103e+02, 4.78751476e+04, 1.53846154e+02, 6.16033748e+04,\n",
       "       1.74358974e+02, 3.59394459e+04, 2.00000000e+01, 1.71566467e+08,\n",
       "       8.00000000e+01, 1.19916353e+08, 1.50000000e+02, 2.72205341e+08,\n",
       "       1.80000000e+02, 1.60194026e+07, 2.10000000e+02, 1.07372241e+08,\n",
       "       3.75000000e-03, 1.50165006e+13, 7.50000000e-03, 1.46816015e+13,\n",
       "       1.87500000e-02, 1.20623075e+13, 2.37500000e-02, 1.12749638e+13,\n",
       "       2.62500000e-02, 1.11949613e+13, 1.46076351e+12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:, :-1]\n",
    "Y_train = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set is : 0.9951456310679612\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set is : {}\".format(clf.score(X_train, Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
